{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a5147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,regularizers, losses\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv3D, Flatten, BatchNormalization, MaxPooling3D\n",
    "from tensorflow.keras.layers import concatenate, Reshape, UpSampling3D\n",
    "import random\n",
    "import open3d as o3d\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "# import pyvista as pv\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd34900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for binary crossentropy custom loss function\n",
    "\n",
    "class CustomLoss_BCE(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, y_true, y_pred):\n",
    "        \n",
    "        _epsilon = tf.convert_to_tensor(0.000001, y_pred.dtype.base_dtype)\n",
    "        y_pred = tf.clip_by_value(y_pred, _epsilon, 1 - _epsilon)\n",
    "\n",
    "        s1 = tf.math.subtract(1.0, y_true)\n",
    "        s2 = tf.math.subtract(1.0, y_pred)\n",
    "        \n",
    "        a = tf.math.multiply_no_nan(tf.math.log(y_pred), y_true)\n",
    "        b = tf.math.multiply_no_nan(tf.math.log(s2), s1)\n",
    "        out = -(20*a + b)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c708b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Input data\n",
    "\n",
    "# folder_path = ''\n",
    "# c=0\n",
    "# files_input1 = []\n",
    "# for filename in glob.glob(os.path.join(folder_path, \"pCIR_area2_rratio_lim.mat\")):\n",
    "#     files_input1.append(filename)\n",
    "\n",
    "# print(len(files_input1))\n",
    "# print(files_input1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumptions of minimum and maximum value for x,y and z for generating the voxel grid \n",
    "\n",
    "min_bound=[-16, -16, -2]\n",
    "max_bound=[16,16,2]\n",
    "voxel_size=0.25\n",
    "\n",
    "x_lim = int((max_bound[0] - min_bound[0])/voxel_size);\n",
    "y_lim = int((max_bound[1] - min_bound[1])/voxel_size);\n",
    "z_lim = int((max_bound[2] - min_bound[2])/voxel_size);\n",
    "\n",
    "# print(x_lim, y_lim, z_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bd290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the input data in the required format for testing similar format is used for ML model training\n",
    "\n",
    "if(os.path.exists(\"X_all_area2.npy\")):\n",
    "    Xp_all_area2 = np.load(\"X_all_area2.npy\")\n",
    "else:\n",
    "    import mat73\n",
    "    filename_inp = files_input1[0]\n",
    "    with open(filename_inp, 'r') as f:\n",
    "        rf_signal = mat73.loadmat(f.name)['Pwr_RTP']\n",
    "        Xp_all_area2= rf_signal\n",
    "    np.save(\"X_all_area2\", Xp_all_area2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f082844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting x, y and z values to our assumed bounds of voxel grid coordinates\n",
    "\n",
    "def convert2(x, y, z):\n",
    "\n",
    "    x_val = (x - min_bound[0])/voxel_size\n",
    "    y_val = (y - min_bound[1])/voxel_size\n",
    "    z_val = (z - min_bound[2])/voxel_size\n",
    "    \n",
    "    return int(np.floor(x_val)), int(np.floor(y_val)), int(np.floor(z_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88725d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pcd(arr, threshold):\n",
    "    c1 = 0\n",
    "    pcd_points = np.zeros((x_lim*y_lim*z_lim,3))\n",
    "    for i in range(x_lim):\n",
    "        for j in range(y_lim):\n",
    "            for k in range(z_lim):\n",
    "                if(arr[i,j,k] > threshold):\n",
    "                    X = -16+(i)*voxel_size + voxel_size/2\n",
    "                    Y = -16+(j)*voxel_size + voxel_size/2\n",
    "                    Z = -2+(k)*voxel_size + voxel_size/2 \n",
    "                    pcd_points[c1,0] = X\n",
    "                    pcd_points[c1,1] = Y\n",
    "                    pcd_points[c1,2] = Z\n",
    "                    c1=c1+1\n",
    "    pcl = o3d.geometry.PointCloud()\n",
    "    pcl.points = o3d.utility.Vector3dVector(pcd_points[:c1, :])\n",
    "    return pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing via prediction output modification\n",
    "\n",
    "import math\n",
    "\n",
    "def out_modification(arr):\n",
    "    c = 3*(10**8)\n",
    "    sample_dist = (1/1.76)*c*(10**(-9))\n",
    "    output = np.zeros((128, 128, 16))\n",
    "    \n",
    "    for theta in range(0, 180, 2):\n",
    "        for phi in range(-180, 180):\n",
    "            max_val = -100\n",
    "            ind_x = -1\n",
    "            ind_y = -1\n",
    "            ind_z = -1\n",
    "            \n",
    "            for i in range(93):\n",
    "                r = i*sample_dist\n",
    "                xx = r*math.sin(math.radians(theta))*math.cos(math.radians(phi))\n",
    "                yy = r*math.sin(math.radians(theta))*math.sin(math.radians(phi))\n",
    "                zz = r*math.cos(math.radians(theta))\n",
    "    \n",
    "                [x, y, z] = convert2(xx, yy, zz)\n",
    "    \n",
    "                if(x > -1 and x < x_lim and y > -1 and  y < y_lim and z > -1 and  z < z_lim and output[x,y,z]!=1):\n",
    "                    if(max_val < arr[x,y,z]):\n",
    "                        max_val = arr[x,y,z]\n",
    "                        ind_x = x\n",
    "                        ind_y = y\n",
    "                        ind_z = z\n",
    "                \n",
    "            output[ind_x, ind_y, ind_z] = 1\n",
    "#             print(ind_x,ind_y, ind_z)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e92d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the testing data\n",
    "\n",
    "X_test = Xp_all_area2\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    min_val = np.min(X_test[i,:,:,:100])           \n",
    "    max_val = np.max(X_test[i,:,:,:100])\n",
    "    X_test[i,:,:,:100] = (X_test[i,:,:,:100] - min_val)/(max_val - min_val)\n",
    "    \n",
    "\n",
    "X_test=np.reshape(X_test[:,:,:,:100],(-1,6400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f164f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NN model-1 \n",
    "\n",
    "input_1 = Input(shape = (6400,), name = 'input_1')\n",
    "x = Dense(4096, activation='relu')(input_1)\n",
    "\n",
    "\n",
    "x = tf.reshape(x, [-1,32,32,4,1])\n",
    "\n",
    "\n",
    "x = UpSampling3D((3, 3, 3))(x)\n",
    "\n",
    "\n",
    "x = Conv3D(2,kernel_size = (13,13,2),activation='relu')(x)\n",
    "\n",
    "x = Conv3D(4,kernel_size = (13,13,3),activation='relu')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv3D(8,kernel_size = (9,9,2),activation='sigmoid')(x)\n",
    "\n",
    "output = tf.reshape(x, [-1,128,128,16])\n",
    "\n",
    "\n",
    "model = Model(inputs=input_1, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0002,decay_steps=10000,decay_rate=0.9)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=opt, loss=CustomLoss_BCE(),metrics=['binary_accuracy'])\n",
    "# #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading trained ML model weights\n",
    "\n",
    "model.load_weights('model_norm_cae_Ts_CL_ep100_ArrData_woReg_AA13_epc30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for testing data\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directory to store predicted pcd\n",
    "\n",
    "directory = 'Lidar_predicted'\n",
    "parent_dir = ''\n",
    "\n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "if(os.path.exists(path) == False):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfe9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating and saving predicted point clouds in .pcd file\n",
    "\n",
    "samples = X_test.shape[0]\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(\"PCD generation for sample\", i)\n",
    "    \n",
    "#     # Method - 1\n",
    "#     pcl = = generate_pcd(pcl, 0.8)\n",
    "    \n",
    "    \n",
    "    # Method - 2\n",
    "    pcl = out_modification(Y_pred[i,:,:,:])\n",
    "    pcl = generate_pcd(pcl, 0)\n",
    "    \n",
    "    file = \"{}{:05d}{}\".format(\"Lidar_predicted/LidarPred_2\", int(i), '.pcd')\n",
    "    print(file)\n",
    "#     file = ['Lidar_predicted/LidarPred_' + str(file_number.zfill(4)) + '.pcd']\n",
    "    o3d.io.write_point_cloud(file, pcl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
